{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbqLnlpW5ONy"
   },
   "source": [
    "# 오산시 어린이 교통사고 위험지역 도출 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9TEQvjc5ON3"
   },
   "source": [
    "## 1. Data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7WdxmaNZ5ON4"
   },
   "outputs": [],
   "source": [
    "#12/24 GeoSeries 추가\n",
    "from geoband.API import *\n",
    "import pandas as pd\n",
    "import folium\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from geojson import Feature, FeatureCollection, Point, dump\n",
    "from geopandas import GeoSeries\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import pydeck as pdk\n",
    "import shapely\n",
    "import numpy as np\n",
    "plt.rc(\"font\", family = \"Malgun Gothic\")\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/opt/app-root/src/Osan_si/Osan_data_preprocessing/'\n",
    "df_osan_grid=gpd.read_file(path + 'df_osan_grid.geojson')\n",
    "df_road_info=gpd.read_file(path + 'df_road_info.geojson')\n",
    "\n",
    "df1_parking=gpd.read_file(path + 'df1_parking.geojson')\n",
    "df2_grid_accident=gpd.read_file(path + 'df2_grid_accident.geojson')\n",
    "df4_pop=gpd.read_file(path + 'df4_pop.geojson')\n",
    "df5_junior_pop=gpd.read_file(path + 'df5_junior_pop.geojson')\n",
    "df6_product_pop=gpd.read_file(path + 'df6_product_pop.geojson')\n",
    "df7_senior_pop=gpd.read_file(path + 'df7_senior_pop.geojson')\n",
    "df8_floating_pop=gpd.read_file(path + 'df8_floating_pop.geojson')\n",
    "df9_protection_area=gpd.read_file(path + 'df9_protection_area.geojson')\n",
    "df10_school=gpd.read_file(path + 'df10_school.geojson')\n",
    "df11_elementary_district=gpd.read_file(path + 'df11_elementary_district.geojson')\n",
    "df12_middle_district=gpd.read_file(path + 'df12_middle_district.geojson')\n",
    "df13_kinder=gpd.read_file(path + 'df13_kinder.geojson')\n",
    "df15_traffic_cctv=gpd.read_file(path + 'df15_traffic_cctv.geojson')\n",
    "df16_road_sign=gpd.read_file(path + 'df16_road_sign.geojson')\n",
    "df17_crosswalk=gpd.read_file(path + 'df17_crosswalk.geojson')\n",
    "df18_speed_bump=gpd.read_file(path + 'df18_speed_bump.geojson')\n",
    "df19_traffic_light=gpd.read_file(path + 'df19_traffic_light.geojson')\n",
    "df20_cctv=gpd.read_file(path + 'df20_cctv.geojson')\n",
    "df21_sidewalk=gpd.read_file(path + 'df21_sidewalk.geojson')\n",
    "df22_bus_stop=gpd.read_file(path + 'df22_bus_stop.geojson')\n",
    "df23_road=gpd.read_file(path + 'df23_road.geojson')\n",
    "df24_traffic=pd.read_csv(path + 'df24_traffic.csv')\n",
    "df25_traffic_frequency=pd.read_csv(path + 'df25_traffic_frequency.csv')\n",
    "df26_traffic_time=pd.read_csv(path + 'df26_traffic_time.csv')\n",
    "df27_building=gpd.read_file(path + 'df27_building.geojson')\n",
    "df28_grid_building=gpd.read_file(path + 'df28_grid_building.geojson')\n",
    "df29_sports=gpd.read_file(path + 'df29_sports.geojson')\n",
    "df30_academy=gpd.read_file(path + 'df30_academy.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JMnjJSbu5ON5"
   },
   "source": [
    "## 2. 분석 기초 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUF_9ivg5ON6"
   },
   "source": [
    "### 1) pydeck 사용을 위해 geometry의 Point, Multilinestring, Multipolygon을 coordinates로 바꿔주기 위한 함수 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 점에서 좌표로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUzuoLAS5ON6"
   },
   "outputs": [],
   "source": [
    "# 12/25 창균 추가\n",
    "def POINT_to_coordinates(geo_data):\n",
    "    geo_data['lat'] = geo_data['geometry'].apply(lambda coord: coord.y)\n",
    "    geo_data['lon'] = geo_data['geometry'].apply(lambda coord: coord.x)\n",
    "    return geo_data\n",
    "\n",
    "# 사용 예\n",
    "# df19_traffic_light = POINT_to_coordinates(df19_traffic_light)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 라인에서 좌표로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHNAWzAT5ON6"
   },
   "outputs": [],
   "source": [
    "# 12/25 창균 추가\n",
    "def MULTILINESTRING_to_coordinates(line_string):\n",
    "    if isinstance(line_string, shapely.geometry.linestring.LineString):\n",
    "        lon, lat = line_string.xy\n",
    "        return [[x, y] for x, y in zip(lon, lat)]\n",
    "    elif isinstance(line_string, shapely.geometry.multilinestring.MultiLineString):\n",
    "        ret = []\n",
    "        for i in range(len(line_string)):\n",
    "            lon, lat = line_string[i].xy\n",
    "            for x, y in zip(lon, lat):\n",
    "                ret.append([x, y])\n",
    "        return ret\n",
    "    \n",
    "# 사용 예\n",
    "# df23_road['coordinates'] = df23_road['geometry'].apply(MULTILINESTRING_to_coordinates)\n",
    "# df23_road = pd.DataFrame(df23_road) # geopanadas 가 아닌 pandas 의 데이터프레임으로 꼭 바꿔줘야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 면에서 좌표로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2DwqAk75ON6"
   },
   "outputs": [],
   "source": [
    "# 12/25 창균 추가\n",
    "def MULTIPOLYGON_to_coordinates(x):\n",
    "    lon, lat = x[0].exterior.xy\n",
    "    return [[x, y] for x, y in zip(lon, lat)]\n",
    "\n",
    "# 사용 예\n",
    "# df_osan_grid['coordinates'] = df_osan_grid['geometry'].apply(MULTIPOLYGON_to_coordinates)\n",
    "# df_osan_grid = pd.DataFrame(df_osan_grid) # geopanadas 가 아닌 pandas 의 데이터프레임으로 꼭 바꿔줘야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wZg_uln5ON7"
   },
   "source": [
    "### 2) 각각의 df의 lon, lat을 geometry의 point로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 좌표에서 점으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GTBvGjT5ON7"
   },
   "outputs": [],
   "source": [
    "# 12/24 정민 수정사항\n",
    "def location_to_point(df):\n",
    "    point_df = gpd.points_from_xy(df.lon, df.lat)\n",
    "    point_df = GeoSeries(point_df)\n",
    "    \n",
    "    col = df.columns\n",
    "    \n",
    "    loc_df = gpd.GeoDataFrame(df[col], geometry = point_df)\n",
    "    \n",
    "    return loc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LDSWZrb5ON7"
   },
   "source": [
    "### 3) sjoin : 격자내 존재하는 좌표 개수의 합을 구하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsyQyH965ON7"
   },
   "outputs": [],
   "source": [
    "def sjoin(grid_info,df, new_col_name, option = 'contains'):\n",
    "    joined= gpd.sjoin(grid_info,df, op=option)\n",
    "    result = joined.groupby('gid').size()\n",
    "    result = result.to_frame().reset_index()\n",
    "    grid_info=pd.merge(grid_info,result, how='outer',on='gid')\n",
    "    \n",
    "    grid_info = grid_info.rename(columns = {0:new_col_name})\n",
    "    grid_info=grid_info.fillna(0)\n",
    "    \n",
    "    return grid_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA 및 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. pydeck 사용을 위한 추가처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 파일에서 실행할 애들\n",
    "# 전처리과정에서 처리시 GeoJson으로 저장할 수 없음.\n",
    "# 시각화할때 필요한 data들이라 시각화 전에만 입력해줘도 됨\n",
    "# geometry to coordinates\n",
    "df4_pop['coordinates'] = df4_pop['geometry'].apply(MULTIPOLYGON_to_coordinates)\n",
    "# df4_pop = pd.DataFrame(df4_pop)\n",
    "\n",
    "# geometry to coordinates\n",
    "df5_junior_pop['coordinates'] = df5_junior_pop['geometry'].apply(MULTIPOLYGON_to_coordinates)\n",
    "# df5_junior_pop = pd.DataFrame(df5_junior_pop)\n",
    "\n",
    "# geometry to coordinates\n",
    "df6_product_pop['coordinates'] = df6_product_pop['geometry'].apply(MULTIPOLYGON_to_coordinates)\n",
    "# df6_product_pop = pd.DataFrame(df6_product_pop)\n",
    "\n",
    "# geometry to coordinates\n",
    "df7_senior_pop['coordinates'] = df7_senior_pop['geometry'].apply(MULTIPOLYGON_to_coordinates)\n",
    "# df7_senior_pop = pd.DataFrame(df7_senior_pop)\n",
    "\n",
    "# geometry to coordinates\n",
    "df11_elementary_district['coordinates'] = df11_elementary_district['geometry'].apply(MULTIPOLYGON_to_coordinates)\n",
    "\n",
    "# geometry to coordinates\n",
    "df21_sidewalk['coordinates'] = df21_sidewalk['geometry'].apply(MULTILINESTRING_to_coordinates)\n",
    "# df21_sidewalk = pd.DataFrame(df21_sidewalk)\n",
    "\n",
    "# geometry to coordinates\n",
    "df23_road['coordinates'] = df23_road['geometry'].apply(MULTILINESTRING_to_coordinates)\n",
    "# df23_road = pd.DataFrame(df23_road)\n",
    "\n",
    "# geometry to coordinates\n",
    "df27_building['coordinates'] = df27_building['geometry'].apply(MULTIPOLYGON_to_coordinates)\n",
    "# df27_building = pd.DataFrame(df27_building)\n",
    "\n",
    "# geometry to coordinates\n",
    "df28_grid_building['coordinates'] = df28_grid_building['geometry'].apply(MULTIPOLYGON_to_coordinates)\n",
    "# df28_grid_building = pd.DataFrame(df28_grid_building)\n",
    "\n",
    "# geometry to coordinates\n",
    "df_osan_grid['coordinates'] = df_osan_grid['geometry'].apply(MULTIPOLYGON_to_coordinates)\n",
    "# df_osan_grid = pd.DataFrame(df_osan_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2. 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer = pdk.Layer(\n",
    "#     'ScatterplotLayer',\n",
    "#     df16_road_sign,\n",
    "#     get_position=['lon', 'lat'],\n",
    "#     get_radius=15,\n",
    "#     get_fill_color=[180, 0, 200, 140],\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "#     )\n",
    "\n",
    "# center=[127.0772,37.1498]\n",
    "# view_state = pdk.ViewState( \n",
    "#     longitude=center[0], \n",
    "#     latitude=center[1], \n",
    "#     zoom=10\n",
    "# ) \n",
    "# r2 = pdk.Deck(layers=[layer], initial_view_state=view_state,\n",
    "#              map_style='mapbox://styles/mapbox/outdoors-v11',\n",
    "#              mapbox_key = \"pk.eyJ1IjoicmVib3JuMTk5OCIsImEiOiJja2oyZGppZ24wdHJ1MnRtaHU5dm92cnV0In0.8sNxBdHqt8JccQZB-oe3Cg\"\n",
    "#             )\n",
    "\n",
    "# r2.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df23_road['N_road_width'] = df23_road['width'] / df23_road['width'].max()\n",
    "# layer_1 = pdk.Layer(\n",
    "#     'PathLayer',\n",
    "#     df23_road,\n",
    "#     get_path='coordinates',\n",
    "#     get_width='width * 10',\n",
    "#     get_color='[255, 120, 255* N_road_width]',\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "# )\n",
    "\n",
    "# layer_2 = pdk.Layer(\n",
    "#     'ScatterplotLayer',\n",
    "#     df16_road_sign,\n",
    "#     get_position=['lon', 'lat'],\n",
    "#     get_radius=8,\n",
    "#     get_fill_color=[180, 0, 200, 140],\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "#     )\n",
    "\n",
    "# center=[127.0772,37.1498]\n",
    "# view_state = pdk.ViewState(\n",
    "#     longitude=center[0],\n",
    "#     latitude=center[1],\n",
    "#     zoom=13)\n",
    "\n",
    "# r = pdk.Deck(layers=[layer_1, layer_2], initial_view_state=view_state,\n",
    "#              map_style='mapbox://styles/mapbox/outdoors-v11',\n",
    "#              mapbox_key = \"pk.eyJ1IjoicmVib3JuMTk5OCIsImEiOiJja2oyZGppZ24wdHJ1MnRtaHU5dm92cnV0In0.8sNxBdHqt8JccQZB-oe3Cg\"\n",
    "#             )\n",
    "\n",
    "# r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df23_road['N_road_width'] = df23_road['width'] / df23_road['width'].max()\n",
    "# layer_1 = pdk.Layer(\n",
    "#     'PathLayer',\n",
    "#     df23_road,\n",
    "#     get_path='coordinates',\n",
    "#     get_width='width * 10',\n",
    "#     get_color='[255, 120, 255* N_road_width]',\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "# )\n",
    "\n",
    "# layer_2 = pdk.Layer(\n",
    "#     'ScatterplotLayer',\n",
    "#     df16_road_sign,\n",
    "#     get_position=['lon', 'lat'],\n",
    "#     get_radius=8,\n",
    "#     get_fill_color=[180, 0, 200, 140],\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "#     )\n",
    "\n",
    "# layer_2 = pdk.Layer(\n",
    "#     'ScatterplotLayer',\n",
    "#     df10_school,\n",
    "#     get_position=['lon', 'lat'],\n",
    "#     get_radius=16,\n",
    "#     get_fill_color=[180, 0, 200, 140],\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "#     )\n",
    "\n",
    "# center=[127.0772,37.1498]\n",
    "# view_state = pdk.ViewState(\n",
    "#     longitude=center[0],\n",
    "#     latitude=center[1],\n",
    "#     zoom=13)\n",
    "\n",
    "# r = pdk.Deck(layers=[layer_1, layer_2], initial_view_state=view_state,\n",
    "#              map_style='mapbox://styles/mapbox/outdoors-v11',\n",
    "#              mapbox_key = \"pk.eyJ1IjoicmVib3JuMTk5OCIsImEiOiJja2oyZGppZ24wdHJ1MnRtaHU5dm92cnV0In0.8sNxBdHqt8JccQZB-oe3Cg\"\n",
    "#             )\n",
    "\n",
    "# r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df24_traffic\n",
    "# df['N_total_traffic'] = df['all_traffic'] / df['all_traffic'].max()\n",
    "# layer = pdk.Layer( 'PathLayer', \n",
    "#                   df, \n",
    "#                   get_path='link_id', \n",
    "#                   get_width='N_total_traffic*10', \n",
    "#                   get_color='[255, 255 * N_total_traffic, 120]', \n",
    "#                   pickable=True, auto_highlight=True \n",
    "#                  ) \n",
    "\n",
    "# center=[127.0772,37.1498]\n",
    "# view_state = pdk.ViewState(\n",
    "#     longitude=center[0],\n",
    "#     latitude=center[1],\n",
    "#     zoom=13)\n",
    "\n",
    "# r = pdk.Deck(layers=[layer], initial_view_state=view_state,\n",
    "#              map_style='mapbox://styles/mapbox/outdoors-v11',\n",
    "#              mapbox_key = \"pk.eyJ1IjoicmVib3JuMTk5OCIsImEiOiJja2oyZGppZ24wdHJ1MnRtaHU5dm92cnV0In0.8sNxBdHqt8JccQZB-oe3Cg\"\n",
    "#             )\n",
    "\n",
    "# r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer = pdk.Layer('PathLayer', \n",
    "#                   df, \n",
    "#                   get_path='link_id', \n",
    "#                   get_width='N_total_traffic*10', \n",
    "#                   get_color='[255, 255 * N_total_traffic, 120]', \n",
    "#                   pickable=True, auto_highlight=True \n",
    "#                  ) \n",
    "\n",
    "# center=[127.0772,37.1498]\n",
    "# view_state = pdk.ViewState(\n",
    "#     longitude=center[0],\n",
    "#     latitude=center[1],\n",
    "#     zoom=13)\n",
    "\n",
    "# r = pdk.Deck(layers=[layer], initial_view_state=view_state,\n",
    "#              map_style='mapbox://styles/mapbox/outdoors-v11',\n",
    "#              mapbox_key = \"pk.eyJ1IjoicmVib3JuMTk5OCIsImEiOiJja2oyZGppZ24wdHJ1MnRtaHU5dm92cnV0In0.8sNxBdHqt8JccQZB-oe3Cg\"\n",
    "#             )\n",
    "\n",
    "# r.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon_layer = pdk.Layer(\n",
    "#     'PolygonLayer',\n",
    "#     grid_info,\n",
    "#     stroked=False,\n",
    "#     # processes the data as a flat longitude-latitude pair\n",
    "#     get_polygon=\"coordinates\",\n",
    "#     get_fill_color = '[180 * accident_cnt, 0, 200, 140]',\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "#     )\n",
    "\n",
    "# layer = pdk.Layer(\n",
    "#     'ScatterplotLayer',\n",
    "#     df10_school,\n",
    "#     get_position=['lon', 'lat'],\n",
    "#     get_radius=15,\n",
    "#     get_fill_color=[180, 0, 200, 140],\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "#     )\n",
    "\n",
    "# center=[127.0772,37.1498]\n",
    "# view_state = pdk.ViewState(\n",
    "#     longitude=center[0],\n",
    "#     latitude=center[1],\n",
    "#     zoom=13)\n",
    "\n",
    "# r = pdk.Deck(layers=[polygon_layer, layer], initial_view_state=view_state,\n",
    "#              map_style='mapbox://styles/mapbox/outdoors-v11',\n",
    "#              mapbox_key = \"pk.eyJ1IjoicmVib3JuMTk5OCIsImEiOiJja2oyZGppZ24wdHJ1MnRtaHU5dm92cnV0In0.8sNxBdHqt8JccQZB-oe3Cg\"\n",
    "#             )\n",
    "\n",
    "# r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 격자 결합\n",
    "> df1_parking: 격자별 불법주정차 단속지점 수 parking_val\n",
    "\n",
    "> df4_pop: 격자별 인구수 pop_val\n",
    "\n",
    "> df5_junior_pop: 격자별 아이 인구수 junior_val\n",
    "\n",
    "> df8_floating_pop: 격자별 유동인구 수 floating_pop_val\n",
    "    \n",
    "> df10_school: 격자별 학교 수 school_val\n",
    "\n",
    "> df13_kinder: 격자별 유치원 수 kinder_val\n",
    "\n",
    "> df17_crosswalk: 오산시_횡단보도 crosswalk_val\n",
    "\n",
    "> df18_speed_bump:오산시_과속방지턱 수 bump_val\n",
    "\n",
    "> df20_cctv: 오산시_CCTV수 cctv_val\n",
    "\n",
    "> df21_sidewalk: 오산시_인도 sidewalk_val\n",
    "\n",
    "> df22_bus_stop: 격자별 버스 정류장 수 Bus_stop_val\n",
    "\n",
    "> df28_grid_building: 격자별 빌딩 밀도 density_building_val\n",
    "    \n",
    "> df29_sports: 격자별 체육시설 수 sports_val\n",
    "\n",
    "> df30_academy: 격자별 학원 수 academy_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인구 수와 유소년 인구 수 concat\n",
    "grid_info=pd.concat([df4_pop,df5_junior_pop['junior_val']],axis=1)\n",
    "grid_info\n",
    "\n",
    "# 격자별 건물 수 concat \n",
    "grid_info=pd.concat([grid_info,df28_grid_building['grid_building_val']],axis=1)\n",
    "grid_info\n",
    "\n",
    "#grid_info와 df18_speed_bump를 합치기 위하여 변경\n",
    "grid_info=gpd.GeoDataFrame(grid_info)\n",
    "df18_speed_bump=location_to_point(df18_speed_bump)\n",
    "\n",
    "grid_info=sjoin(grid_info,df18_speed_bump,'bump_val')\n",
    "\n",
    "#유동인구를 함치기 위하여 변경\n",
    "df8_floating_pop=location_to_point(df8_floating_pop)\n",
    "\n",
    "\n",
    "temp=df8_floating_pop.groupby(['lon','lat'])['8_23'].mean()\n",
    "temp=pd.DataFrame(temp)\n",
    "temp=temp.reset_index()\n",
    "# sjoin을 위하여 geodataframe으로 변경\n",
    "temp=gpd.GeoDataFrame(temp)\n",
    "temp=location_to_point(temp)\n",
    "# grid_info와 sjoin\n",
    "test=gpd.sjoin(grid_info,temp,op='contains')\n",
    "test = test.groupby('gid')['8_23'].sum().to_frame().reset_index()\n",
    "grid_info=pd.merge(grid_info,test,how='outer',on='gid')\n",
    "grid_info=grid_info.rename(columns={'8_23':'floating_pop_val'})\n",
    "#null값 처리\n",
    "grid_info=grid_info.fillna(0)\n",
    "grid_info\n",
    "\n",
    "grid_info=grid_info[['gid','geometry','coordinates','pop_val','junior_val','grid_building_val','bump_val','floating_pop_val']]\n",
    "grid_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school = df10_school.copy()\n",
    "kinder = df13_kinder.copy()\n",
    "sports = df29_sports.copy()\n",
    "CCTV = df15_traffic_cctv.copy()\n",
    "academy = df30_academy.copy()\n",
    "\n",
    "# 창균\n",
    "grid_info = sjoin(grid_info, df1_parking, 'pk_val')\n",
    "grid_info = sjoin(grid_info, df22_bus_stop, 'bus_stop_val')\n",
    "grid_info = sjoin(grid_info, df17_crosswalk, 'crosswalk_val')\n",
    "grid_info = sjoin(grid_info, df21_sidewalk, 'sidewalk_val')\n",
    "\n",
    "# 정민\n",
    "grid_info = sjoin(grid_info, school, \"school_val\")\n",
    "grid_info = sjoin(grid_info, kinder, 'kinder_val')\n",
    "grid_info = sjoin(grid_info, sports, 'sports_val')\n",
    "grid_info = sjoin(grid_info, academy, 'academy_val')\n",
    "grid_info = sjoin(grid_info, CCTV, \"traffic_cctv_val\")\n",
    "\n",
    "grid_info=sjoin(grid_info,df20_cctv,'cctv_val')\n",
    "grid_info=sjoin(grid_info,df19_traffic_light,'traffic_light_val')\n",
    "\n",
    "grid_info = grid_info.join(df2_grid_accident, how = 'left', lsuffix = '', rsuffix = '_r')\n",
    "grid_info.drop(['gid_r', 'geometry_r'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 버퍼 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 학교 버퍼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_center = df_osan_grid['geometry'].centroid\n",
    "# grid_center : 오산시 100m * 100m격자의 중앙점\n",
    "dist_100m = Point(grid_center[0]).distance(Point(grid_center[1])) # 중앙점간의 거리는 100m\n",
    "dist = dist_100m * 10\n",
    "# dist => 300m\n",
    "\n",
    "\n",
    "\n",
    "def point_to_buf(data_point, point_name,buf_name, n=5,): # parameter: data_point => 학교위치정보, 학원위치정보등등 point_name => school_name등, buf_name => buffer에 해당하는 해당 영역 1로 지정, n -> buf 거리지정\n",
    "    global dist_100m\n",
    "    dist = dist_100m * n\n",
    "    \n",
    "    data_buf = gpd.GeoDataFrame()\n",
    "    data_buf['geometry'] = data_point.buffer(distance = dist, cap_style=1)\n",
    "    data_buf = gpd.GeoDataFrame(data_point[point_name], geometry=data_buf.geometry)\n",
    "    ret_df = gpd.overlay(df_osan_grid, data_buf, how='intersection')\n",
    "    ret_df[buf_name] = 1\n",
    "    \n",
    "    return ret_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_cores = point_to_buf(school,'school_name',\"school_buffer_val\" ,10)\n",
    "school_cores=school_cores.groupby(['gid'])['school_buffer_val'].count()\n",
    "school_cores=pd.DataFrame(school_cores).reset_index()\n",
    "grid_info=pd.concat([grid_info,school_cores['school_buffer_val']],axis=1)\n",
    "grid_info=grid_info.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 도로 링크 버퍼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df23_road.columns\n",
    "gdf_col = ['link_id', 'max_speed', 'road_name', 'road_no', 'road_rank',\n",
    "       'link_type', 'road_type', 'up_lanes', 'dw_lanes', 'oneway', 'length',\n",
    "       'width', 'car_lane', 'num_cross', 'barrier',]\n",
    "\n",
    "gdf_road = gpd.GeoDataFrame(df23_road[gdf_col], geometry= df23_road.geometry)\n",
    "gdf_road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_buf = gpd.GeoDataFrame()\n",
    "road_buf['geometry'] = gdf_road.geometry.buffer(distance = (dist_100m/10), cap_style=3)\n",
    "road_buf = gpd.GeoDataFrame(df23_road[gdf_col], geometry=road_buf.geometry)\n",
    "road_buf = gpd.overlay(df_osan_grid, road_buf, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_buf.geometry.plot(figsize=(10,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# layer_1 = pdk.Layer(\n",
    "#     'PathLayer',\n",
    "#     road_buf,\n",
    "#     get_path='coordinates',\n",
    "#     get_width='width * 10',\n",
    "#     get_color='[255, 120, 255]',\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "# )\n",
    "# grid_layer = pdk.Layer(\n",
    "#     'PolygonLayer',\n",
    "#     df_osan_grid,\n",
    "#     stroked=False,\n",
    "#     # processes the data as a flat longitude-latitude pair\n",
    "#     get_polygon=\"coordinates\",\n",
    "#     get_fill_color = '[100, 0, 100, 140]',\n",
    "#     pickable=True,\n",
    "#     auto_highlight=True\n",
    "# )\n",
    "\n",
    "# center=[127.0772,37.1498]\n",
    "# view_state = pdk.ViewState(\n",
    "#     longitude=center[0],\n",
    "#     latitude=center[1],\n",
    "#     zoom=13\n",
    "# )\n",
    "\n",
    "# r = pdk.Deck(\n",
    "#     layers=[layer_1, grid_layer,layer], initial_view_state=view_state,\n",
    "#     map_style='mapbox://styles/mapbox/outdoors-v11',\n",
    "#     mapbox_key = \"pk.eyJ1IjoicmVib3JuMTk5OCIsImEiOiJja2oyZGppZ24wdHJ1MnRtaHU5dm92cnV0In0.8sNxBdHqt8JccQZB-oe3Cg\"\n",
    "# )\n",
    "\n",
    "# r.to_html()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 격자 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data_set, column):\n",
    "    m = data_set[column].min()\n",
    "    M = data_set[column].max()\n",
    "    data_set[column]=(data_set[column] - m)/(M - m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 과정\n",
    "#한번만 돌려요\n",
    "normalization_list=grid_info.columns[3:]\n",
    "for i in normalization_list:\n",
    "    normalization(grid_info,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정민 머신러닝 적용실습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "grid_target = grid_info['accident_cnt']\n",
    "y_target = grid_target\n",
    "X_data = grid_info\n",
    "X_data = X_data.drop(['gid', 'geometry', 'coordinates','accident_cnt'], axis=1, inplace=False)\n",
    "\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 0, n_estimators =1000)\n",
    "neg_mse_scores = cross_val_score(rf, X_data, y_target, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rmse_scores = np.sqrt(-1*neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "print(np.round(neg_mse_scores, 4))\n",
    "print(np.round(rmse_scores, 2))\n",
    "print(avg_rmse)\n",
    "print(neg_mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cv_prediction(model, X_data, y_target):\n",
    "    neg_mse_scores = cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "    rmse_scores = np.sqrt(-1*neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "    print(\"####\", model.__class__.__name__, ' #####')\n",
    "    print(' 5 교차 검증의 평균 RMSE : {0:.3f}'.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "dt_grid = DecisionTreeRegressor(random_state = 0, max_depth = 4)\n",
    "gb_grid = GradientBoostingRegressor(random_state=0, n_estimators=1000)\n",
    "xgb_grid = XGBRegressor(n_estimators=1000)\n",
    "lgb_grid = LGBMRegressor(n_estimators=1000)\n",
    "models = [dt_grid, rf, gb_grid,xgb_grid, lgb_grid]\n",
    "for model in models:\n",
    "    get_model_cv_prediction(model, X_data, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "rf.fit(X_data, y_target)\n",
    "feature_series = pd.Series(data = rf.feature_importances_, index=X_data.columns)\n",
    "feature_series = feature_series.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y=feature_series.index)\n",
    "\n",
    "lgb_grid.fit(X_data, y_target)\n",
    "feature_series_lgb = pd.Series(data=lgb_grid.feature_importances_, index=X_data.columns)\n",
    "feature_series_lgb = feature_series_lgb.sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series_lgb, y=feature_series_lgb.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = rf.predict(X_data)\n",
    "a = pd.Series(rf_pred)\n",
    "# a = a.rename(columns = {0:'Pred'})\n",
    "b = pd.Series(y_target)\n",
    "\n",
    "# a['accident_cnt'] = b['accident_cnt']\n",
    "a.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.sort_values(ascending=False)\n",
    "a.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.plot()\n",
    "b = b.sort_values(ascending=False)\n",
    "b.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#회귀분석\n",
    "corr_list=grid_info.columns[3:-1]\n",
    "x=grid_info[corr_list]\n",
    "y=grid_info['accident_cnt']\n",
    "regression=linear_model.LinearRegression()\n",
    "regression.fit(x,y)\n",
    "print(regression.intercept_)\n",
    "print(regression.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.genmod.generalized_estimating_equations import GEE\n",
    "from statsmodels.genmod.cov_struct import (Exchangeable,\n",
    "    Independence,Autoregressive)\n",
    "from statsmodels.genmod.families import Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fam = Poisson()\n",
    "ind = Autoregressive()\n",
    "model1 = GEE.from_formula(\"accident_cnt ~ pop_val + junior_val \", \"gid\", grid_info, cov_struct=ind, family=fam)\n",
    "result1 = model1.fit()\n",
    "print(result1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.predstd import wls_prediction_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, x)\n",
    "result=model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상관관계 heatmap 시각화\n",
    "import seaborn as sns\n",
    "corr=grid_info.corr(method='pearson')\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(data = corr, annot=True,fmt = '.2f', linewidths=.5, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expr = \"\"\"accident_cnt ~ pop_val + junior_val + grid_building_val + bump_val + floating_pop_val + pk_val\n",
    "#         + bus_stop_val + crosswalk_val + sidewalk_val + school_val + kinder_val\n",
    "#         + sports_val + academy_val + cctv_val + traffic_light_val + school_buffer_val\"\"\"\n",
    "\n",
    "expr = \"\"\"accident_cnt ~ floating_pop_val + pk_val\n",
    "        + bus_stop_val + crosswalk_val + sidewalk_val + school_val + kinder_val\n",
    "        + sports_val + cctv_val + traffic_light_val + school_buffer_val\"\"\"\n",
    "\n",
    "y, X = dmatrices(expr, grid_info, return_type='dataframe')\n",
    "\n",
    "poisson_fit = sm.GLM(y, X, family=sm.families.Poisson()).fit()\n",
    "poisson_predict = poisson_fit.predict()\n",
    "\n",
    "a = pd.DataFrame(poisson_predict)\n",
    "a = a.rename(columns = {0:'Pred'})\n",
    "b = pd.DataFrame(grid_info['accident_cnt'])\n",
    "\n",
    "a['accident_cnt'] = b['accident_cnt']\n",
    "normalization(a, 'Pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Pred'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['accident_cnt'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE 너무 큼\n",
    "a['residual'] = a['Pred'] - a['accident_cnt']\n",
    "a['residual'] = a['residual'] ** (1/2)\n",
    "a['residual'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(poisson_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균과 분산이 같지 않아 포아송 분포를 사용할 수 없다 가 맞지만 교수님은 poisson 쓰라고 하심.\n",
    "print(a['Pred'].mean())\n",
    "print(a['Pred'].var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상관관계 heatmap 시각화\n",
    "import seaborn as sns\n",
    "corr=grid_info.corr(method='pearson')\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(data = corr, annot=True,fmt = '.2f', linewidths=.5, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expr = \"\"\"accident_cnt ~ pop_val + junior_val + grid_building_val + bump_val + floating_pop_val + pk_val\n",
    "#         + bus_stop_val + crosswalk_val + sidewalk_val + school_val + kinder_val\n",
    "#         + sports_val + academy_val + cctv_val + cctv_val + traffic_light_val + school_buffer_val\"\"\"\n",
    "\n",
    "expr = \"\"\"accident_cnt ~ pop_val + junior_val + grid_building_val + bump_val + floating_pop_val + pk_val\n",
    "        + bus_stop_val + crosswalk_val + sidewalk_val + school_val + kinder_val\n",
    "        + sports_val + academy_val + cctv_val + cctv_val + traffic_light_val + school_buffer_val\"\"\"\n",
    "\n",
    "y, X = dmatrices(expr, grid_info, return_type='dataframe')\n",
    "\n",
    "NB_fit = sm.GLM(y, X, family=sm.families.NegativeBinomial()).fit()\n",
    "\n",
    "NB_predict = NB_fit.predict()\n",
    "\n",
    "c = pd.DataFrame(NB_predict)\n",
    "c = c.rename(columns = {0:'Pred'})\n",
    "d = pd.DataFrame(grid_info['accident_cnt'])\n",
    "\n",
    "c['accident_cnt'] = d['accident_cnt']\n",
    "normalization(c, 'Pred')\n",
    "\n",
    "print(NB_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['accident_cnt'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c['Pred'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요한 변수 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expr = \"\"\"accident_cnt ~ pop_val + junior_val + grid_building_val + bump_val + floating_pop_val + pk_val\n",
    "#         + bus_stop_val + crosswalk_val + sidewalk_val + school_val + kinder_val\n",
    "#         + sports_val + academy_val + cctv_val + cctv_val + traffic_light_val + school_buffer_val\"\"\"\n",
    "\n",
    "expr = \"\"\"accident_cnt ~ junior_val + floating_pop_val + pk_val\n",
    "        + bus_stop_val + crosswalk_val + sidewalk_val + school_val + kinder_val\n",
    "        + sports_val + academy_val + cctv_val + traffic_cctv_val + traffic_light_val + school_buffer_val\"\"\"\n",
    "\n",
    "y, X = dmatrices(expr, grid_info, return_type='dataframe')\n",
    "\n",
    "NB_fit = sm.GLM(y, X, family=sm.families.NegativeBinomial()).fit()\n",
    "\n",
    "NB_predict = NB_fit.predict()\n",
    "\n",
    "e = pd.DataFrame(NB_predict)\n",
    "e = e.rename(columns = {0:'Pred'})\n",
    "f = pd.DataFrame(grid_info['accident_cnt'])\n",
    "\n",
    "e['accident_cnt'] = f['accident_cnt']\n",
    "normalization(e, 'Pred')\n",
    "\n",
    "print(NB_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e['Pred'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e['accident_cnt'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_grid_accident['accident_cnt'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Osan_data_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
